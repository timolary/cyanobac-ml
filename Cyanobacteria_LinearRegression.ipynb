{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "\n",
    "from data_manager import get_data\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2, ds3 = get_data()\n",
    "#print(ds2)\n",
    "#print(ds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y\n",
    "X = np.array(ds3.drop(['target', 'NP_Cya_bio'], axis=1))\n",
    "y = np.array(ds3['target'])\n",
    "y_reg = np.array(ds3['NP_Cya_bio']) #for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_reg, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the X's\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4331216573107976\n",
      "[  453312.08223563  -818274.02190306 -1715702.92705677 22265050.0175068\n",
      "  -263676.33980401 11993814.38669171 10201003.8236107    300020.02127503\n",
      "  2706418.64463787]\n"
     ]
    }
   ],
   "source": [
    "#Linear regression\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y_reg)\n",
    "print(model.score(X, y_reg))\n",
    "print(model.coef_) # get theta coefficients (model params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try again using Bagrow's method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.289198606271777\n",
      "Number of test samples =  287\n",
      "[[83  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "# define the model\n",
    "model = LogisticRegression(solver = \"liblinear\", penalty = 'l2')\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions using the trained model on unseen data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# measure the performance \n",
    "ac = accuracy_score(y_test,predicted)\n",
    "\n",
    "# report the results \n",
    "print(\"Accuracy is: \",ac);\n",
    "\n",
    "print (\"Number of test samples = \",len(y_test))\n",
    "confusion = metrics.confusion_matrix(y_test, predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to try for logistic regression:\n",
    "- ds2 vs ds3\n",
    "- features scaled vs not\n",
    "- use cross validation\n",
    "- get performance summary with recall and ROC AUC and confusion matrix\n",
    "- add polynomial features\n",
    "- add regularization: try elastic net and/or Lasso (=L1?)\n",
    "- use random search and cross validation to tune hyperparameters, find best model (specify scoring metric as recall/F1/AUC?):\n",
    "    - C (inverse of regularization strength --> smaller value = more regularization)\n",
    "    - solver (choice depends on choice of regularization)\n",
    "    - penalty (form of regularization?)\n",
    "    - l1_ratio: ratio between 0 and 1 passed for elasticnet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
