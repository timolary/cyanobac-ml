{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "from data_manager import get_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TP    DP    Cl    TN      TempC   Chla  Secchi   NP_Cya_bio  target  \\\n",
      "0     39.2  16.2  13.0  0.61   6.494521   1.41     0.5          0.0     0.0   \n",
      "1     36.8  14.8  17.5  0.45  13.700000   9.67     1.1          0.0     0.0   \n",
      "2     50.1  27.4  12.1  0.55  14.500000   2.04     0.7          0.0     0.0   \n",
      "4     59.6  32.6  12.0  0.65  17.700000   4.13     0.6          0.0     0.0   \n",
      "5     77.3  47.9  10.5  0.62  22.500000   1.74     0.6          0.0     0.0   \n",
      "...    ...   ...   ...   ...        ...    ...     ...          ...     ...   \n",
      "3629  53.4  16.8   8.0  0.69  25.600000  27.50     1.1  389000000.0     0.0   \n",
      "3631  83.4  33.9   8.3  0.71  23.700000  23.94     1.0  133000000.0     0.0   \n",
      "3632  94.2  40.7   8.7  0.90  22.300000  50.16     1.0  443000000.0     1.0   \n",
      "3634  68.8  42.6   9.6  0.74  13.400000  10.22     1.4    9460000.0     0.0   \n",
      "3636  79.4  49.7   9.2  0.76   9.200000  11.81     1.3    6510000.0     0.0   \n",
      "\n",
      "            N:P  Month  \n",
      "0     34.410892      4  \n",
      "1     27.040633      5  \n",
      "2     24.276000      5  \n",
      "4     24.116777      6  \n",
      "5     17.736355      6  \n",
      "...         ...    ...  \n",
      "3629  28.573274      8  \n",
      "3631  18.825411      9  \n",
      "3632  21.127289      9  \n",
      "3634  23.784578     10  \n",
      "3636  21.166315     10  \n",
      "\n",
      "[1431 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "ds2, ds3 = get_data()\n",
    "print(ds3)\n",
    "#print(len(ds3[ds3['target'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y\n",
    "X = np.array(ds3.drop(['target', 'NP_Cya_bio'], axis=1))\n",
    "y = np.array(ds3['target'])\n",
    "y_reg = np.array(ds3['NP_Cya_bio']) #for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       283\n",
      "         1.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.99       287\n",
      "   macro avg       1.00      0.75      0.83       287\n",
      "weighted avg       0.99      0.99      0.99       287\n",
      "\n",
      "[[283   0]\n",
      " [  2   2]]\n",
      "[0.14112875 0.09231273 0.08191765 0.09365499 0.07206457 0.33692823\n",
      " 0.05802903 0.08136422 0.04259983]\n"
     ]
    }
   ],
   "source": [
    "#Random forest!! (Should I scale the data? No, not for trees or forests or PCA.)\n",
    "trees = 500\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = trees, max_features = 'auto', criterion = 'gini', class_weight = None, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "scores = metrics.classification_report(y_test, y_pred)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(scores)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#Feature importance:\n",
    "model.fit(X,y)\n",
    "feature_importances = model.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 192 is smaller than n_iter=800. Running 192 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done 224 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=4)]: Done 350 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 512 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 710 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 944 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed:  3.0min finished\n",
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                        criterion='entropy', max_depth=None, max_features='sqrt',\n",
       "                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False),\n",
       " 0.483537296037296]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning hyperparams properly:\n",
    "model = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#Use CV to find best parameters: \n",
    "best_estimators = []\n",
    "distros = dict(n_estimators = [10, 50, 100, 500], \n",
    "               max_features = ['sqrt', 'log2'],\n",
    "               min_samples_split = [2,3,4,5,6,7],\n",
    "               criterion = ['gini', 'entropy'],\n",
    "               class_weight = ['balanced', None])\n",
    "\n",
    "search = RandomizedSearchCV(model, distros, scoring='f1', refit='f1', verbose=5, cv=5, n_iter=800, n_jobs=4, pre_dispatch='2*n_jobs', random_state = 42)\n",
    "search = search.fit(X_train, y_train)\n",
    "best_estimators.append(search.best_estimator_)\n",
    "best_estimators.append(search.best_score_)\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "F1 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       283\n",
      "         1.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.99       287\n",
      "   macro avg       1.00      0.75      0.83       287\n",
      "weighted avg       0.99      0.99      0.99       287\n",
      "\n",
      "[[283   0]\n",
      " [  2   2]]\n",
      "[0.10378074 0.05778298 0.14347255 0.12517641 0.03460575 0.20239728\n",
      " 0.23739454 0.03527471 0.06011504]\n"
     ]
    }
   ],
   "source": [
    "#Testing the best RF model\n",
    "model = best_estimators[0]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Testing\n",
    "y_pred = model.predict(X_test)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "print('F1', f1)\n",
    "scores = metrics.classification_report(y_test, y_pred)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(scores)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#Feature importance:\n",
    "model.fit(X,y)\n",
    "feature_importances = model.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       283\n",
      "         1.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.99       287\n",
      "   macro avg       1.00      0.75      0.83       287\n",
      "weighted avg       0.99      0.99      0.99       287\n",
      "\n",
      "[[283   0]\n",
      " [  2   2]]\n",
      "[0.11703532 0.08118965 0.08003595 0.11125677 0.07682259 0.29985984\n",
      " 0.08423189 0.08241517 0.06715281]\n"
     ]
    }
   ],
   "source": [
    "#Just for fun, let's try ExtraTrees, too. \n",
    "model = ExtraTreesClassifier(n_estimators = 500, criterion = 'gini', class_weight = None, random_state = 42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "scores = metrics.classification_report(y_test, y_pred)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(scores)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#The same results. Boo.\n",
    "\n",
    "#Feature importance:\n",
    "model.fit(X,y)\n",
    "feature_importances = model.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 192 is smaller than n_iter=800. Running 192 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 158 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=4)]: Done 248 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=4)]: Done 374 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=4)]: Done 536 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 734 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed:  2.0min finished\n",
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "                      criterion='entropy', max_depth=None, max_features='sqrt',\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False),\n",
       " 0.44454295704295704]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning hyperparams properly:\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "#Use CV to find best parameters: \n",
    "best_estimators = []\n",
    "distros = dict(n_estimators = [10, 50, 100, 500], \n",
    "               max_features = ['sqrt', 'log2'],\n",
    "               min_samples_split = [2,3,4,5,6,7],\n",
    "               criterion = ['gini', 'entropy'],\n",
    "               class_weight = ['balanced', None])\n",
    "\n",
    "search = RandomizedSearchCV(model, distros, scoring='f1', refit='f1', verbose=5, cv=5, n_iter=800, n_jobs=4, pre_dispatch='2*n_jobs')\n",
    "search = search.fit(X_train, y_train)\n",
    "best_estimators.append(search.best_estimator_)\n",
    "best_estimators.append(search.best_score_)\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "F1 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       283\n",
      "         1.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.99       287\n",
      "   macro avg       1.00      0.75      0.83       287\n",
      "weighted avg       0.99      0.99      0.99       287\n",
      "\n",
      "[[283   0]\n",
      " [  2   2]]\n",
      "[0.1260745  0.05872883 0.08968917 0.10816764 0.04725456 0.19245005\n",
      " 0.20842596 0.05175708 0.1174522 ]\n"
     ]
    }
   ],
   "source": [
    "#Testing the best ET model\n",
    "model = best_estimators[0]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Testing\n",
    "y_pred = model.predict(X_test)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "print('F1', f1)\n",
    "scores = metrics.classification_report(y_test, y_pred)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(scores)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#Feature importance:\n",
    "model.fit(X,y)\n",
    "feature_importances = model.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04585    0.03725391 0.04604401 0.04269727 0.02843661 0.70201554\n",
      " 0.02394555 0.03594694 0.03781018]\n",
      "validation score: 0.5747329326549762\n",
      "test score: 0.45141993840839256\n"
     ]
    }
   ],
   "source": [
    "#Finally, let's try a random forest regression!\n",
    "\n",
    "#Split the data for regression:\n",
    "X_train, X_test, yr_train, yr_test = train_test_split(X, y_reg, test_size=0.20, random_state = 42)\n",
    "\n",
    "trees = 500\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = trees, max_features = 'auto', oob_score = True, random_state = 42)\n",
    "model.fit(X_train, yr_train)\n",
    "print(model.feature_importances_)\n",
    "print('validation score:', model.oob_score_) #returns R^2 values using out of bag values as test sets\n",
    "     \n",
    "#Hmm. Doesn't seem great.\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = metrics.r2_score(yr_test, y_pred)\n",
    "print('test score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 96 is smaller than n_iter=800. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 480 out of 480 | elapsed:  2.0min finished\n",
      "/Users/mahaliaclark/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                       max_features='log2', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False), 0.1688903739754343]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning hyperparams properly:\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#Use CV to find best parameters: \n",
    "best_estimators = []\n",
    "distros = dict(n_estimators = [10, 50, 100, 500], \n",
    "               max_features = ['sqrt', 'log2'],\n",
    "               min_samples_split = [2,3,4,5,6,7])\n",
    "\n",
    "search = RandomizedSearchCV(model, distros, scoring='r2', refit='r2', verbose=5, cv=5, n_iter=800, n_jobs=4, pre_dispatch='2*n_jobs')\n",
    "search = search.fit(X_train, yr_train)\n",
    "best_estimators.append(search.best_estimator_)\n",
    "best_estimators.append(search.best_score_)\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11477587 0.05697833 0.08451433 0.0786059  0.04989842 0.46342385\n",
      " 0.05082612 0.06512972 0.03584745]\n",
      "0.538809447659649\n",
      "0.46226178564522946\n"
     ]
    }
   ],
   "source": [
    "#Testing RF Regressor\n",
    "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "                       max_features='log2', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=True, random_state=42,\n",
    "                       verbose=0, warm_start=False)\n",
    "model.fit(X_train, yr_train)\n",
    "print(model.feature_importances_)\n",
    "print(model.oob_score_) #returns R^2 values using out of bag values as test sets\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = metrics.r2_score(yr_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Conclusion...\n",
    "It doesn't seem like Random Forest does that well for this data set. On the other hand, it does a better job than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune: n_estimators, max_features, and min_samples_split, and class_weight by cross-validated grid search. \n",
    "\n",
    "Tuning hyperparams with RandomizedSearchCV did slightly worse than the default parameters + n_estimators chosen with 5-fold cross validation, so let's stick with the simpler models. \n",
    "\n",
    "No difference between Random Forest and Extra Trees for classification, so we'll ONLY use results from the first random forest classification and the first random forest regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
